{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tensor Inspection\n",
    "\n",
    "This notebook details the process of identifying and tracking the values of tensors in a given network with an example using Mask RCNN. First, we generate a small dataset consisting of a single image from the coco data. We then look at how to track the tensors within Mask RCNN using that image. Finally, we track the gradients that backpropogate through the network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /mask-rcnn-tensorflow/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
      "\n",
      "WARNING:tensorflow:From /mask-rcnn-tensorflow/tensorpack/tfutils/optimizer.py:19: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /mask-rcnn-tensorflow/tensorpack/tfutils/sesscreate.py:24: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.18.0-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:117: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.18.0-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:143: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/dist-packages/numba/errors.py:131: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import json\n",
    "#os.environ['TF_CUDNN_DETERMINISTIC'] = 'true'\n",
    "os.environ['TENSORPACK_FP16'] = 'true'\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    import tensorflow as tf\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import tensorpack.utils.viz as tpviz\n",
    "from tensorpack import *\n",
    "from tensorpack.tfutils.common import get_tf_version_tuple\n",
    "sys.path.append('/mask-rcnn-tensorflow/MaskRCNN')\n",
    "from model.generalized_rcnn import ResNetFPNModel\n",
    "from config import finalize_configs, config as cfg\n",
    "from eval import DetectionResult, predict_image, multithread_predict_dataflow, EvalCallback\n",
    "from performance import ThroughputTracker, humanize_float\n",
    "from data import get_eval_dataflow, get_train_dataflow, get_batch_train_dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = ResNetFPNModel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.DATA.BASEDIR = '/data/small_sample/'\n",
    "cfg.BACKBONE.WEIGHTS = '/data/pretrained-models/ImageNet-R50-AlignPadding.npz'\n",
    "tf.set_random_seed(cfg.TRAIN.SEED)\n",
    "fix_rng_seed(cfg.TRAIN.SEED)\n",
    "np.random.seed(cfg.TRAIN.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train dataflow\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[1124 19:32:53 @dataset.py:52]\u001b[0m Instances loaded from /data/small_sample/annotations/instances_train2017.json.\n",
      "\u001b[32m[1124 19:32:53 @dataset.py:52]\u001b[0m Instances loaded from /data/small_sample/annotations/instances_train2017.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 6599.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[1124 19:32:53 @tensorpack_utils.py:342]\u001b[0m Load Load annotations for train2017 finished, time:0.0060sec.\n",
      "\u001b[32m[1124 19:32:53 @tensorpack_utils.py:342]\u001b[0m Load Load annotations for train2017 finished, time:0.0060sec.\n",
      "Done loading roidbs\n",
      "\u001b[32m[1124 19:32:53 @data.py:624]\u001b[0m Filtered 0 images which contain no non-crowd groudtruth boxes. Total #images for training: 25\n",
      "\u001b[32m[1124 19:32:53 @data.py:624]\u001b[0m Filtered 0 images which contain no non-crowd groudtruth boxes. Total #images for training: 25\n",
      "Batching roidbs\n",
      "Done batching roidbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_RNG_SEED' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4492ac437072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_train_dataflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE_PER_GPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfinalize_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mask-rcnn-tensorflow/MaskRCNN/data.py\u001b[0m in \u001b[0;36mget_batch_train_dataflow\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m    669\u001b[0m     aug = AugmentorList(\n\u001b[1;32m    670\u001b[0m          [CustomResize(cfg.PREPROC.TRAIN_SHORT_EDGE_SIZE, cfg.PREPROC.MAX_SIZE),\n\u001b[0;32m--> 671\u001b[0;31m           Flip(horiz=True)])\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;31m# aug = imgaug.AugmentorList([CustomResize(cfg.PREPROC.TRAIN_SHORT_EDGE_SIZE, cfg.PREPROC.MAX_SIZE)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mask-rcnn-tensorflow/tensorpack_dataflow.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, horiz, vert, prob)\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mprob\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mof\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \"\"\"\n\u001b[0;32m--> 855\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhoriz\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot do both horiz and vert. Please use two Flip instead.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mask-rcnn-tensorflow/tensorpack_dataflow.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mask-rcnn-tensorflow/tensorpack_dataflow.py\u001b[0m in \u001b[0;36mreset_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;34m\"\"\" reset rng and other state \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mask-rcnn-tensorflow/tensorpack_utils.py\u001b[0m in \u001b[0;36mget_rng\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    153\u001b[0m     seed = (id(obj) + os.getpid() +\n\u001b[1;32m    154\u001b[0m             int(datetime.now().strftime(\"%Y%m%d%H%M%S%f\"))) % 4294967295\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_RNG_SEED\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RNG_SEED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_RNG_SEED' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataflow = get_batch_train_dataflow(cfg.TRAIN.BATCH_SIZE_PER_GPU)\n",
    "finalize_configs(is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_init = get_model_loader(cfg.BACKBONE.WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have our data and the model is setup. In order to export a gradient from the graph, we need to add a print statement to the tensor we want to track. For example, say we want to export the second to last layer of the backbone network (c4). Add this import to the top of the backbone.py file:\n",
    "\n",
    "```from performance import print_runtime_tensor, print_runtime_tensor_loose_branch```\n",
    "\n",
    "The, just after the c4 tensor is created in the network, add this line:\n",
    "\n",
    "```c4 = print_runtime_tensor(\\\"tensor_c4_forward\\\", c4)```\n",
    "\n",
    "Similarly, say we want to output a list of tensors. Perhaps the full output of the fpn (p23456). We can use something like:\n",
    "\n",
    "```p23456 = [print_runtime_tensor(\\\"tensor_p23456_{}_forward\\\".format(i), j) for i,j in enumerate(p23456)]```\n",
    "\n",
    "On the other hand, we might want to see a tensor that isn't actually used later in the graph, which means it wouldn't normally execute such that we can output it. This can be done using the function:\n",
    "\n",
    "`print_runtime_tensor_loose_branch`\n",
    "\n",
    "For this, you need a downstream trigger tesnor to force the print of the tensor of interest. Say we have a tensor `t5` that isn't used in the graph, but `t1` is. We can print `t5` with:\n",
    "\n",
    "```t1 = print_runtime_tensor_loose_branch(\\\"tensor_t5_forward\\\", t5, trigger_tensor=t1)```\n",
    "\n",
    "Finally, say we want to print the gradients of the backwards pass. This is a little more complicated. Add this gradient printer class to the generalized_rcnn.py file:\n",
    "\n",
    "```\n",
    "class GradientPrinter(tf.train.Optimizer):\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "    def compute_gradients(self, *args, **kwargs):\n",
    "        return self.opt.compute_gradients(*args, **kwargs)\n",
    "    def apply_gradients(self, gradvars, global_step=None, name=None):\n",
    "        old_grads, v = zip(*gradvars)\n",
    "        old_grads = [print_runtime_tensor(\"tensor_{}_backward\".format(i.name), j) for i,j in zip(v, old_grads)]\n",
    "        gradvars = list(zip(old_grads, v))\n",
    "        return self.opt.apply_gradients(gradvars, global_step, name)\n",
    "```\n",
    "\n",
    "Inside the detection model class, modify the optimizer to pass through the gradient printer.\n",
    "\n",
    "```\n",
    "opt = tf.train.MomentumOptimizer(lr, 0.9)\n",
    "opt = GradientPrinter(opt)\n",
    "```\n",
    "\n",
    "Once the print function has been added, run the paragraph below with the capture magic function to catch the printed output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed example\n",
    "\n",
    "Let's work through all the steps of tracking a few tensors in the graph, using the fpn example above. First, open the `generalized_rcnn.py` file in the mask rcnn model. \n",
    "\n",
    "Add the import for to print a runtime tensor.\n",
    "\n",
    "<img src=\"assets/import_printer.png\" style=\"width: 600px;\">\n",
    "\n",
    "At the end of the fpn, add the print_runtime_tensor function. Remember that this function returns the same tensor (which is necessary to put the print command in the graph). Also, the p23456 object output from the fpn is a list, so we can print all tensors in the list with\n",
    "\n",
    "<img src=\"assets/print_comprehension.png\" style=\"width: 800px;\">\n",
    "\n",
    "If you want to get more information on this tensor, you can also find it in the graph using tensorboard. Based on the fpn file, these tensors follow the naming convention `posthoc_3x3_p{}` for p2-5 while p6 is named with `max_pool`. To use tensorboard, navigate to the log directory of you model, then select tensorboard with current directory from the new menu in the upper right corner.\n",
    "\n",
    "<img src=\"assets/start_tensorboard.png\" style=\"width: 800px;\">\n",
    "\n",
    "This will open tensorboard in a new tab. It might take a few seconds to load, since this is a large model. Once it's loaded you can search `posthoc_3x3` or `max_pool` under the graphs tab to find the fpn. The entire fpn subgraph looks like\n",
    "\n",
    "<img src=\"assets/tensorboard.png\" style=\"width: 800px;\">\n",
    "\n",
    "Before we run the model and get these tensors, let's also add in a print function for the backwards pass, so we can get the gradients. This is a little trickier, because it requires including a new optimizer, but you can follow the example from above. In the `generalized_rcnn.py` file, add this to the section just below the GradientClipOptimizer\n",
    "\n",
    "<img src=\"assets/add_optimizer.png\" style=\"width: 800px;\">\n",
    "\n",
    "Then include the optimizer just after the initial model optimizer.\n",
    "\n",
    "<img src=\"assets/call_optimizer.png\" style=\"width: 800px;\">\n",
    "\n",
    "Now when you run the model, the gradients in p23456 and all backward pass gradients will print to stdout. This is a lot of data that we would rather not have printing as the model runs, so within this notebook, we can supress and capture the output by adding `%%capture cap_out --no-stderr` at the top of the cell running the model. Also, it's a good idea to initially only run a single forward and backward pass by setting `steps_per_epoch` and `max_epoch` to 1.\n",
    "\n",
    "<img src=\"assets/model_config.png\" style=\"width: 600px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincfg = TrainConfig(\n",
    "            model=MODEL,\n",
    "            data=QueueInput(train_dataflow),\n",
    "            steps_per_epoch=1,\n",
    "            max_epoch=1,\n",
    "            session_init=session_init,\n",
    "            session_config=None,\n",
    "            starting_epoch=cfg.TRAIN.STARTING_EPOCH\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SimpleTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap_out --no-stderr\n",
    "launch_train_with_config(traincfg, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As long as you followed the convention of `tensor_[name]_forward` and `tensor_[name]_backward` the two cells below will split the output, and convert the tensors from strings to numeric lists. Note that it's generally a bad idea to print out these lists in the notebook, as they can be extremely large, and cause the notebook to crash. Instead, they can be written to an output file. \n",
    "\n",
    "Note that these two paragraphs can take a few minutes to run, as the tensors they parse can be quite large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_tensors = {i.split(\"_forward \")[0] : \\\n",
    "                   literal_eval(re.sub(\"\\s+\", \", \", i.split(\"_forward \")[1])) \\\n",
    "                   for i in tqdm.tqdm([j for j in \\\n",
    "                                       cap_out.stdout.split(\"[runtime_tensor] tensor_\")[1:] \\\n",
    "                                       if \"_forward \" in j])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_tensors = {i.split(\"_backward \")[0] : \\\n",
    "                    literal_eval(re.sub(\"\\s+\", \", \", i.split(\"_backward \")[1])) \\\n",
    "                    for i in tqdm.tqdm([j for j in \\\n",
    "                                        cap_out.stdout.split(\"[runtime_tensor] tensor_\")[1:] \\\n",
    "                                        if \"_backward \" in j])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some statistics about the tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forward Tensor Shape\")\n",
    "for i,j in forward_tensors.items():\n",
    "    print(\"{} : {}\".format(i, np.array(j).shape))\n",
    "    \n",
    "print(\"\\nBackward Tensor Shape\")\n",
    "for i,j in backward_tensors.items():\n",
    "    print(\"{} : {}\".format(i, np.array(j).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forward Tensor Means\")\n",
    "for i,j in forward_tensors.items():\n",
    "    print(\"{} : {}\".format(i, np.array(j).mean()))\n",
    "    \n",
    "print(\"\\nBackward Tensor Means\")\n",
    "for i,j in backward_tensors.items():\n",
    "    print(\"{} : {}\".format(i, np.array(j).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can save the tensors to json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/logs/forward_p23456.json', 'w') as outfile:\n",
    "    json.dump(forward_tensors, outfile)\n",
    "    \n",
    "with open('/logs/backward.json', 'w') as outfile:\n",
    "    json.dump(backward_tensors, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
